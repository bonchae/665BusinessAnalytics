{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZ7QMAOQr25bugl7rFWRon"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Set a seed for reproducibility\n","np.random.seed(42)\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"U2FhtK8-tIWP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import fetch_olivetti_faces\n","\n","# Load the Olivetti faces dataset\n","faces_data = fetch_olivetti_faces(shuffle=True, random_state=42)\n","faces = faces_data.data\n","targets = faces_data.target"],"metadata":{"id":"s-tjEAPktOGa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Rows = Individual face images (400 total)\n","- Columns = Pixel positions (4,096) plus person identifier\n","- Cells = Grayscale intensity values for each pixel"],"metadata":{"id":"bCJXwNntt0H1"}},{"cell_type":"code","source":["# data defition\n","n_samples, n_features = faces.shape\n","n_faces = len(np.unique(targets))\n","print(f\"Dataset: {n_samples} images\")\n","print(f\"Image size: 64x64 pixels = {n_features} dimensions\")\n","print(f\"Number of different people: {n_faces}\")"],"metadata":{"id":"ON_rNNBas8_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a DataFrame with the face data\n","\n","# First, create a DataFrame with the pixel values\n","pixel_columns = [f'pixel_{i}' for i in range(faces.shape[1])]\n","faces_df = pd.DataFrame(faces, columns=pixel_columns)\n","\n","# Add the target (person identifier) as a column\n","faces_df['person_id'] = targets\n","\n","print(\"First 5 rows of the DataFrame:\")\n","faces_df.head()"],"metadata":{"id":"LY8BDTdTs9CU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We're displaying actual photos of real people from the dataset - specifically, the first 12 images from the Olivetti faces dataset"],"metadata":{"id":"y73fO9h4t9Zx"}},{"cell_type":"code","source":["# Display some original face images\n","n_row, n_col = 3, 4\n","plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n","plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n","\n","for i in range(n_row * n_col):\n","    plt.subplot(n_row, n_col, i + 1)\n","    plt.imshow(faces[i].reshape((64, 64)), cmap=plt.cm.gray)\n","    plt.title(f\"Person #{targets[i]}\", size=12)\n","    plt.xticks(())\n","    plt.yticks(())\n","\n","plt.suptitle(\"Original Face Images (64x64 pixels = 4,096 dimensions each)\",\n","             fontsize=16)\n","plt.show()"],"metadata":{"id":"JH6ecxYgs9IP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The original images above are represented in **4,096 dimensions (64 Ã— 64 pixels)**.\n","\n","The images below have been reconstructed using only **66 principal components**. Despite this significant reduction in dimensionality, the reconstructed images retain most of the important visual information, demonstrating how PCA effectively captures the underlying structure of the data."],"metadata":{"id":"2ybN4ANfuS4H"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","\n","# Apply PCA to reduce to 66 components\n","n_components = 66\n","pca = PCA(n_components=n_components, whiten=True, random_state=42)\n","faces_pca = pca.fit_transform(faces)\n","faces_reconstructed = pca.inverse_transform(faces_pca)\n","\n","# Plot the reconstructed faces\n","plt.figure(figsize=(2. * n_col, 2.26 * n_row))\n","plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n","\n","for i in range(n_row * n_col):\n","    plt.subplot(n_row, n_col, i + 1)\n","    plt.imshow(faces_reconstructed[i].reshape((64, 64)), cmap=plt.cm.gray)\n","    plt.title(f\"Person #{targets[i]}\", size=12)\n","    plt.xticks(())\n","    plt.yticks(())\n","\n","plt.suptitle(f\"Reconstructed Faces Using {n_components} PCA Components\", fontsize=16)\n","plt.show()"],"metadata":{"id":"pkVYsaPls9LF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Applications: Face recognition\n","\n","  - Netflix Recommendation System (latent space): Compressing massive user-item matrix into a lower-dimensional latent space.\n","  - Intel Sensor Compression\n","  - Gene Expression Analysis (NIH)"],"metadata":{"id":"Ao5Q_BgEuY5r"}},{"cell_type":"markdown","source":["<img src=\"https://hellopm.co/wp-content/uploads/2024/07/hipertextual-si-te-vas-netflix-no-olvides-descargar-mi-actividad-mi-lista-2019814675.webp\" width=500>"],"metadata":{"id":"z4XQfMQxudVA"}},{"cell_type":"code","source":[],"metadata":{"id":"1-bmbl5ks9QK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jzSy3AA3s9Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TDkY7zP2s9VU"},"execution_count":null,"outputs":[]}]}